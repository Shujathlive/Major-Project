{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Keras Implementation\n",
    "Using CNN to classify standing and sitting postures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from keras.models import Sequential\n",
    "#from keras.layers import Conv2D , MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D , MaxPooling2D , Flatten , Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating Data and splitting into respective training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 464 images belonging to 2 classes.\n",
      "Found 18 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = ImageDataGenerator(rescale = 1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
    "test_data = ImageDataGenerator(rescale=1./25)\n",
    "train = train_data.flow_from_directory('training_data',target_size=(64,64),batch_size = 32,class_mode='binary')\n",
    "test = test_data.flow_from_directory('test',target_size=(64,64),batch_size=32,class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Resampling Technique to avoid Overfitting\n",
    "\n",
    "By using sklearn's cross validation Kfold function, resampling into 10 seperate rows of train data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(n_estimators=100)\n",
    "#Simple K-Fold cross validation. 10 folds.\n",
    "cv = cross_validation.KFold(len(train), n_folds=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 30752)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               3936384   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 3,937,409\n",
      "Trainable params: 3,937,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3),input_shape=(64,64,3),activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units= 128 , activation = 'relu'))\n",
    "model.add(Dense(units=1,activation = 'sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer = 'adam',loss='binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4000/4000 [==============================] - 708s 177ms/step - loss: 0.0478 - acc: 0.9879 - val_loss: 0.9992 - val_acc: 0.8889\n",
      "Epoch 2/5\n",
      "4000/4000 [==============================] - 613s 153ms/step - loss: 0.0044 - acc: 0.9988 - val_loss: 0.8857 - val_acc: 0.9444\n",
      "Epoch 3/5\n",
      "4000/4000 [==============================] - 637s 159ms/step - loss: 0.0022 - acc: 0.9994 - val_loss: 0.8857 - val_acc: 0.9444\n",
      "Epoch 4/5\n",
      "4000/4000 [==============================] - 613s 153ms/step - loss: 0.0019 - acc: 0.9995 - val_loss: 0.8857 - val_acc: 0.9444\n",
      "Epoch 5/5\n",
      "4000/4000 [==============================] - 611s 153ms/step - loss: 0.0010 - acc: 0.9997 - val_loss: 1.7811 - val_acc: 0.8889\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24a6ec6f5c0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(train,steps_per_epoch=4000,epochs = 5,validation_data=test,validation_steps=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Testing for Data, using Predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import image\n",
    "imagetest = image.load_img('E:/shujath-academics/academics/Projects/Major Project/training_data/sitting/9.jpg',target_size=(64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAAPxUlEQVR4nNVaeZClVXX/nXu/+21v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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x1C8CABFF828>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagetest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagetest = image.img_to_array(imagetest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imagetest = np.expand_dims(imagetest,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sitting': 0, 'standing': 1}"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if result[0][0]==1:\n",
    "    prediction = 'standing'\n",
    "else:\n",
    "    prediction = 'sitting'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result = model.predict(imagetest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sitting'"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
